{"cells":[{"cell_type":"markdown","source":["# Project Overview: Chat with Multiple PDFs\n","![Application Workflow](https://hackernoon.imgix.net/images/7Ug0PkGHNSN2Kd1AXJvurvkWCxF2-g983p9j.jpeg)\n"],"metadata":{"id":"R6xpsXcEXs7W"}},{"cell_type":"markdown","source":["\n","## INTRODUCTION\n","\n","\n","\n","This project aims to create an interactive, user-friendly web application for querying and interacting with content from multiple PDF documents. Using **Streamlit**, the application provides a seamless interface for users to upload PDFs and ask questions about their content. The system processes the uploaded documents, enabling a conversation-like interaction powered by advanced language and embedding models.\n","\n","The project integrates state-of-the-art tools such as **Langchain**, **Ollama Embeddings**, **Chroma**, and a Llama-based conversational model to deliver an efficient and dynamic querying experience.   \n","<img src=\"https://www.astera.com/wp-content/uploads/2024/10/Basic-RAG-Pipeline.jpg\" alt=\"Application Workflow\" width=\"550\"/>"],"metadata":{"id":"Pu8HfzgJSnsS"}},{"cell_type":"markdown","source":["\n","---\n","\n","## Objectives\n","\n","- Develop a **Streamlit-based application** to allow conversational interactions with multiple PDFs.\n","- Utilize AI and vector-based techniques to extract, process, and retrieve relevant information from document content.\n","- Enhance user experience by enabling natural language querying and maintaining a chat history.\n","\n","---\n"],"metadata":{"id":"1Cr-790oTr8t"}},{"cell_type":"markdown","source":["\n","## Requirements\n","\n","### Key Tools and Libraries:\n","1. **Streamlit**:\n","   - Front-end interface for uploading PDF files and handling user interactions.\n","2. **PyPDF2**:\n","   - Extracts text from PDF documents.\n","3. **Langchain**:\n","   - Handles text processing, embeddings, conversational memory, and retrieval-based question-answering.\n","4. **Chroma**:\n","   - Stores text embeddings for fast and efficient vector-based search and retrieval.\n","5. **OllamaEmbeddings**:\n","   - Generates vector representations of the text for semantic understanding.\n","6. **ChatOllama**:\n","   - Enables advanced conversational capabilities using the Llama3.1 model.\n","7. **Custom HTML Templates**:\n","   - Enhances the visual presentation of the chat interface for better user experience.\n"],"metadata":{"id":"wP0fsdVRTr5W"}},{"cell_type":"markdown","source":["# Setting Up the Project Environment\n","\n","To successfully run the application, you need to set up the environment by installing the necessary tools, libraries, and models. Below is a detailed guide to setting up **Ollama**, downloading models, configuring **Chroma**, and running the **Streamlit** application."],"metadata":{"id":"1F7C-EYObZYH"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","### 1. Setting Up Ollama\n","**Ollama** is required to access the language models **Llama3.1** and **nomic-embed-text**, which are crucial for conversational querying and embedding generation.\n","\n","1. **Install Ollama**:\n","   - Visit the [Ollama website](https://ollama.com/) and download the installation package for your operating system.\n","   - For macOS, you can use Homebrew:\n","     ```bash\n","     brew install ollama\n","     ```\n","\n","2. **Download Required Models**:\n","   After installing Ollama, download the models used in the project:\n","   - **nomic-embed-text** for generating vector embeddings.\n","   - **llama3.1** for conversational AI.\n","\n","   Run the following commands:\n","   ```bash\n","   ollama pull nomic-embed-text\n","   ollama pull llama3.1\n","3. **Start Ollam**a:\n","To enable the models, start the Ollama service by running:\n","```bash\n","ollama start\n","\n","### 2. Setting Up Other Dependencies :\n","Chroma is used to store vector embeddings for efficient search and retrieval.\n","\n","1. **Install Chroma using pip**:\n","\n","```bash\n","pip install chromadb\n","```\n","No additional setup is needed as the project automatically initializes and configures Chroma to store embeddings in the directory ./chroma_db.\n","\n","\n","Streamlit provides the user interface for uploading PDFs and interacting with their content.\n","\n","2. **Install Streamlit**: Use pip to install Streamlit:\n","\n","```bash\n","pip install streamlit\n","```\n","\n","3. **Install Other Dependencies** :\n","Install additional Python libraries required for the project:\n","\n","```bash\n","pip install langchain PyPDF2\n","```\n","### 3. Running the Application\n","Once everything is set up, follow these steps to run the application:\n","\n","1. **Prepare the Environment**:\n","Ensure Ollama is running and the required models are downloaded.\n","Start the Ollama service using ollama start.\n","2. **Run the Streamlit Application**:\n","Navigate to the directory containing the ui.py file.\n","Start the Streamlit app by running:\n","```bash\n","streamlit run ui.py\n","```\n","3. **Interact with the Application**:\n","\n","Open the Streamlit app in your browser (usually at http://localhost:8501).\n","Upload your PDF files and start asking questions to interact with the document content.\n"],"metadata":{"id":"Woa2j4SLT3Ct"}},{"cell_type":"markdown","source":["# Code Explanation\n"],"metadata":{"id":"KJQhkYq_Vrl3"}},{"cell_type":"markdown","source":["# 1. Importing Necessary Libraries:"],"metadata":{"id":"tLYgvFiiWnh1"}},{"cell_type":"code","source":["import streamlit as st\n","from PyPDF2 import PdfReader\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain_community.embeddings import OllamaEmbeddings\n","from langchain_community.vectorstores import Chroma\n","from langchain_community.chat_models import ChatOllama\n","from langchain.memory import ConversationBufferMemory\n","from langchain.chains import ConversationalRetrievalChain\n","from htmlTemplates import css, bot_template, user_template"],"metadata":{"id":"vtLscD06T2v0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Streamlit**: Used to create the web application interface.  \n","**PyPDF2**: Used for reading and extracting text from PDF documents.  \n","**Langchain**: Provides tools for text splitting, embeddings, and conversational AI.  \n","**Chroma**: Vector storage system used for storing embeddings to enable fast retrieval.  \n","**OllamaEmbeddings**: Used to convert text into vector embeddings.  \n","**ChatOllama**: Implements the conversational model based on Llama3.1.  \n","**ConversationBufferMemory**: Maintains chat history during the conversation.  \n","**htmlTemplates**: Custom templates to style the chat UI.  "],"metadata":{"id":"bzTkDnEgWDLx"}},{"cell_type":"markdown","source":["# 2. Function to Extract Text from PDFs:"],"metadata":{"id":"db-aE4vuWZGU"}},{"cell_type":"code","source":["def get_pdf_text(pdf_docs):\n","    \"\"\"Extract text from PDF files.\"\"\"\n","    text = \"\"\n","    for pdf in pdf_docs:\n","        pdf_reader = PdfReader(pdf)\n","        for page in pdf_reader.pages:\n","            text += page.extract_text()\n","    return text"],"metadata":{"id":"xf0aaK5TSq3J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This function takes a list of PDF documents and extracts the text from each page of the PDF, concatenating it into one string. The PdfReader class is used for PDF text extraction."],"metadata":{"id":"9pNKX12mWt5F"}},{"cell_type":"markdown","source":["# 3. Function to Split Text into Chunks:\n"],"metadata":{"id":"rdHvg94EWwNt"}},{"cell_type":"code","source":["def get_text_chunks(text):\n","    \"\"\"Split extracted text into smaller chunks.\"\"\"\n","    text_splitter = CharacterTextSplitter(\n","        separator=\"\\n\",\n","        chunk_size=1000,\n","        chunk_overlap=200,\n","        length_function=len\n","    )\n","    chunks = text_splitter.split_text(text)\n","    return chunks"],"metadata":{"id":"ULZsENldTZXs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After extracting text from the PDFs, this function splits the text into smaller, manageable chunks. This is done using Langchainâ€™s CharacterTextSplitter, which splits based on a character limit, ensuring that each chunk is of a reasonable size for processing."],"metadata":{"id":"l-_2fMfUW8vc"}},{"cell_type":"markdown","source":["# 4. Function to Create a Vectorstore:"],"metadata":{"id":"v9-iDGnfW8mn"}},{"cell_type":"code","source":["def get_vectorstore(text_chunks):\n","    \"\"\"Convert the text chunks into a vector store using Ollama embeddings.\"\"\"\n","    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True)\n","    vectorstore = Chroma.from_texts(texts=text_chunks, embedding=embeddings, persist_directory=\"./chroma_db\")\n","    return vectorstore"],"metadata":{"id":"XkJuCo8QW9Fc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here, the text chunks are passed to OllamaEmbeddings to create vector embeddings. These embeddings are then stored in Chroma for efficient similarity search, enabling quick retrieval of relevant chunks based on user queries."],"metadata":{"id":"qEKNU4k7XGHs"}},{"cell_type":"markdown","source":["# 5. Setting up the Conversational Chain:"],"metadata":{"id":"MZCBOSYOXGEN"}},{"cell_type":"code","source":["def get_conversation_chain(vectorstore):\n","    \"\"\"Setup conversational chain with Llama3.1 model.\"\"\"\n","    llm = ChatOllama(model=\"llama3.1\")\n","\n","    memory = ConversationBufferMemory(\n","        memory_key='chat_history', return_messages=True)\n","    conversation_chain = ConversationalRetrievalChain.from_llm(\n","        llm=llm,\n","        retriever=vectorstore.as_retriever(),\n","        memory=memory\n","    )\n","    return conversation_chain"],"metadata":{"id":"tzFXLYI2XMcH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this function, a ChatOllama conversational model is initialized. The model is paired with ConversationBufferMemory to maintain a history of the conversation. The ConversationalRetrievalChain is created, linking the model, vector store, and memory together for efficient query handling."],"metadata":{"id":"vpYjdQNoXM0a"}},{"cell_type":"markdown","source":["# 6. Handling User Input:"],"metadata":{"id":"snSAfz-0XMw7"}},{"cell_type":"code","source":["def handle_userinput(user_question):\n","    \"\"\"Handle user input and display chat history.\"\"\"\n","    response = st.session_state.conversation({'question': user_question})\n","    st.session_state.chat_history = response['chat_history']\n","\n","    for i, message in enumerate(st.session_state.chat_history):\n","        if i % 2 == 0:\n","            st.write(user_template.replace(\n","                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n","        else:\n","            st.write(bot_template.replace(\n","                \"{{MSG}}\", message.content), unsafe_allow_html=True)"],"metadata":{"id":"gMG_ALpjXS7O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This function handles user queries. When a question is asked, it sends the query to the conversational chain and updates the chat history. The conversation is displayed in the app interface using custom HTML templates for both user and bot messages."],"metadata":{"id":"Y5kRXlJHXTXV"}},{"cell_type":"markdown","source":["# 7. Main Function to Run the Streamlit App:"],"metadata":{"id":"PZTZGUUmXTTy"}},{"cell_type":"code","source":["def main():\n","    \"\"\"Main function to run the Streamlit app.\"\"\"\n","    st.set_page_config(page_title=\"Chat with multiple PDFs\",\n","                       page_icon=\":books:\")\n","    st.write(css, unsafe_allow_html=True)\n","\n","    if \"conversation\" not in st.session_state:\n","        st.session_state.conversation = None\n","    if \"chat_history\" not in st.session_state:\n","        st.session_state.chat_history = None\n","\n","    st.header(\"Chat with multiple PDFs :books:\")\n","    user_question = st.text_input(\"Ask a question about your documents:\")\n","    if user_question:\n","        handle_userinput(user_question)\n","\n","    with st.sidebar:\n","        st.subheader(\"Your documents\")\n","        pdf_docs = st.file_uploader(\n","            \"Upload your PDFs here and click on 'Process'\", accept_multiple_files=True)\n","        if st.button(\"Process\"):\n","            with st.spinner(\"Processing\"):\n","                # get pdf text\n","                raw_text = get_pdf_text(pdf_docs)\n","\n","                # get the text chunks\n","                text_chunks = get_text_chunks(raw_text)\n","\n","                # create vector store with Ollama embeddings\n","                vectorstore = get_vectorstore(text_chunks)\n","\n","                # create conversation chain with Llama3.1\n","                st.session_state.conversation = get_conversation_chain(vectorstore)"],"metadata":{"id":"xmx0rlNwXZUP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The main() function is the entry point of the Streamlit app. It configures the page, handles user input, and manages PDF file uploads. Once PDFs are uploaded, the text is processed, and the conversation chain is set up, enabling users to ask questions and receive responses."],"metadata":{"id":"ODf9gXCpXaG4"}},{"cell_type":"markdown","source":["# RESULTS"],"metadata":{"id":"zCWM45qEcaQp"}},{"cell_type":"markdown","source":["## 1. Page d'acceuil :  \n","<img src=\"https://i.imgur.com/8HrUImt.png\" alt=\"Application Workflow\" width=\"500\"/>\n"],"metadata":{"id":"fyGa9h7Ie3wk"}},{"cell_type":"markdown","source":["## 2. Uploading Files\n","<img src=\"https://i.imgur.com/1JR8mAN.png\" alt=\"Application Workflow\" width=\"300\"/>  <img src=\"https://i.imgur.com/emSowx5.png\" alt=\"Application Workflow\" width=\"300\"/>\n","\n"],"metadata":{"id":"ZK-0Rgk7lPMe"}},{"cell_type":"markdown","source":["## 3. Querying the database and getting the answer\n","<img src=\"https://i.imgur.com/lwFLxMl.png\" alt=\"Application Workflow\" width=\"700\"/>\n","\n","<img src=\"https://i.imgur.com/BDCYpq8.png\" alt=\"Application Workflow\" width=\"500\"/> <img src=\"https://i.imgur.com/gaT40Db.png\" alt=\"Application Workflow\" width=\"500\"/>\n","\n","\n"],"metadata":{"id":"jOiPkXNnlPJE"}},{"cell_type":"markdown","source":["# Conclusion"],"metadata":{"id":"YMLadpw_XaDT"}},{"cell_type":"markdown","source":["This application combines Streamlit, Langchain, and Ollama to provide an interactive and powerful tool for querying multiple PDF documents. The user-friendly interface enables document uploading and seamless conversations with the content.  \n","\n","\n"],"metadata":{"id":"etVBt-H8XjEm"}}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1733864662245}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}